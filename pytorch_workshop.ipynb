{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ced85796-78fc-49b9-b97f-424292761b1c",
   "metadata": {},
   "source": [
    "# pytorchで簡単にニューラルネットワークを作ろう"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e08552c-f994-4814-9324-a09789046bd6",
   "metadata": {},
   "source": [
    "## ニューラルネットワークとは\n",
    "\n",
    "- できることを見ると\n",
    "  - 回帰問題（数値予測）と分類問題が解けるやつ\n",
    "  - 入力と期待される出力の組（教師データ）を与えればいい感じに補間してくれるやつ\n",
    "    - 損失関数は上手に設定する必要がある\n",
    "- 構成するパーツを見ると\n",
    "  - 人工ニューロンがいっぱい繋がったやつ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b19e53-0d30-4ef4-b249-6bcb57f23424",
   "metadata": {},
   "source": [
    "## 人工ニューロンとは（数式は覚えなくていい）\n",
    "\n",
    "- $d$ 個の入力（=入力ベクトル）$\\boldsymbol{x}=(1,x_1,\\dots,x_d)^{T}$ を受け、\n",
    "  重み付け和を計算し、適当な関数（活性化関数）に通して出力するやつ\n",
    "  - 単に内積で表せるようにダミーの $1$ を第0次元に付け足している（cf. 同次座標系）\n",
    "- ニューロンの持つパラメータは\n",
    "  - 重み $\\boldsymbol{w}=(w_0,w_1,\\dots,w_d)^{T}$\n",
    "  - 活性化関数 $f$\n",
    "    - しばしば同じ層のニューロンは同じ活性化関数を使う\n",
    "- 出力は $f(\\boldsymbol{w}^{T}\\boldsymbol{x})=f(w_0+w_1x_1+\\dots+w_dx_d)$\n",
    "\n",
    "![ニューラルネットワークは多数のニューロンが接続されている](./resources/figures/neural_network.png)\n",
    "![ニューロンの入出力](./resources/figures/artificial_neuron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7d9919-f7c6-4569-8442-f7b7459b1333",
   "metadata": {},
   "source": [
    "## ニューラルネットワークの万能近似定理（普遍性定理）\n",
    "\n",
    "3層ニューラルネットワークはいくつかの条件のもと、その重みを調節することによって出力の誤差を任意の正数まで減らすことができる\n",
    "\n",
    "現在は活性化関数はSigmoidalな関数でなくても良いとされている"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c811f-4022-407b-ab62-6bb345330218",
   "metadata": {},
   "source": [
    "## ニューラルネットワークで分類問題を解くには\n",
    "\n",
    "$c$ クラス分類問題を解くならば、$c$ 出力のニューラルネットワークにする\n",
    "\n",
    "入力を与えてForward計算をしたとき、出力層において最大の値を取っているノードのクラスに分類されたとする"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f01b46d-8e5c-4ac3-9218-443e471b8d52",
   "metadata": {},
   "source": [
    "## 画像分類問題を解く\n",
    "\n",
    "### CIFAR-10とは\n",
    "\n",
    "32x32サイズのRGBカラー画像が、10クラス各6000個用意されたデータセット。\n",
    "\n",
    "### ニューラルネットワークに画像を入力する（一般論として）\n",
    "\n",
    "サイズ $A \\times B$、3チャンネル（RGB）固定であるとするならば、flattenして $3AB$ 次元のベクトルとして入力すれば良い\n",
    "\n",
    "### CIFAR-10の場合\n",
    "\n",
    "32x32 のRGB画像なので、入力は32x32x3=3072次元とする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eef0aa0-c439-4ef9-bdca-48e147de71d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.302583  [    0/50000]\n",
      "loss: 2.127244  [ 5000/50000]\n",
      "loss: 2.018109  [10000/50000]\n",
      "loss: 1.816076  [15000/50000]\n",
      "loss: 1.847676  [20000/50000]\n",
      "loss: 1.511767  [25000/50000]\n",
      "loss: 1.423052  [30000/50000]\n",
      "loss: 1.619048  [35000/50000]\n",
      "loss: 1.817378  [40000/50000]\n",
      "loss: 1.490311  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 45.4%, Avg loss: 1.539818 \n",
      "\n",
      "[[181  28  78  23  29  16   9  17  89  34]\n",
      " [ 72 197  41  54  27  30  51  23  83 158]\n",
      " [ 24   6 123  41  67  24  30   9   6   6]\n",
      " [ 33  21  84 167  79 112  94  67  30  26]\n",
      " [  5   0  83  19 143  27  43  29   2   2]\n",
      " [ 24   7 116 142 103 175  52  82  13   8]\n",
      " [ 20  24  67  77  89  58 184  42   4  40]\n",
      " [ 42  31 101 105 135 131  88 195  20  48]\n",
      " [141  70  48  26  24  24  15  19 193  93]\n",
      " [ 33  61  13  30   5   7  21  38  32 174]]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.520112  [    0/50000]\n",
      "loss: 1.598086  [ 5000/50000]\n",
      "loss: 1.506683  [10000/50000]\n",
      "loss: 1.425364  [15000/50000]\n",
      "loss: 1.541919  [20000/50000]\n",
      "loss: 1.404128  [25000/50000]\n",
      "loss: 1.613222  [30000/50000]\n",
      "loss: 1.477885  [35000/50000]\n",
      "loss: 1.124047  [40000/50000]\n",
      "loss: 1.471905  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 50.4%, Avg loss: 1.388776 \n",
      "\n",
      "[[192  41  76  29  26  19   7  18 100  43]\n",
      " [ 36 191  16  20  11   5  11   3  66  74]\n",
      " [ 48  12 149  62  96  64  52  27  21  13]\n",
      " [ 27  11  91 169  82 136  89  77  35  25]\n",
      " [ 22  13 125  70 169  54  91  73   6   8]\n",
      " [  9   4  46  93  37 170  20  48   3   4]\n",
      " [ 13  14  51  68  87  49 190  27   5  27]\n",
      " [ 16  18  72  68  90 105  41 189  14  31]\n",
      " [105  45  27  16  10   8   9   8 194  48]\n",
      " [ 77 149  42  59  24  31  58  56  73 192]]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.393071  [    0/50000]\n",
      "loss: 1.244283  [ 5000/50000]\n",
      "loss: 1.461331  [10000/50000]\n",
      "loss: 1.218504  [15000/50000]\n",
      "loss: 1.470865  [20000/50000]\n",
      "loss: 1.449525  [25000/50000]\n",
      "loss: 1.625779  [30000/50000]\n",
      "loss: 1.249898  [35000/50000]\n",
      "loss: 1.490094  [40000/50000]\n",
      "loss: 1.243240  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 52.8%, Avg loss: 1.333969 \n",
      "\n",
      "[[195  64  80  41  41  25  16  40 110  60]\n",
      " [ 31 193  13  19   8   4  11   2  51  92]\n",
      " [ 41   7 159  55  78  68  31  23  19  12]\n",
      " [ 18   8  57 166  45 127  40  63  23  16]\n",
      " [ 20  11 132  95 178  95  86  96   4  11]\n",
      " [  7   2  34  77  20 162   7  36   2   4]\n",
      " [ 14  20  80 110 102  61 195  47  10  24]\n",
      " [  7  14  51  59  70  94  22 188   6  31]\n",
      " [103  57  38  19  14  15   8  11 194  50]\n",
      " [ 58 138  30  46  16  21  24  45  53 190]]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.537950  [    0/50000]\n",
      "loss: 1.271070  [ 5000/50000]\n",
      "loss: 1.448663  [10000/50000]\n",
      "loss: 1.485642  [15000/50000]\n",
      "loss: 1.063285  [20000/50000]\n",
      "loss: 1.259519  [25000/50000]\n",
      "loss: 1.398976  [30000/50000]\n",
      "loss: 1.560618  [35000/50000]\n",
      "loss: 1.161097  [40000/50000]\n",
      "loss: 1.424856  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.0%, Avg loss: 1.304927 \n",
      "\n",
      "[[188  47  56  19  29  13   7  20  72  46]\n",
      " [ 16 185   3   9   3   1   3   0  32  71]\n",
      " [ 68  18 174  75 120  97  51  42  33  21]\n",
      " [ 31  14  74 173  63 122  49  66  23  25]\n",
      " [ 20   7  91  66 169  53  51  74   6  12]\n",
      " [ 13   5  61 117  51 171  21  70   6  12]\n",
      " [ 19  36  80 119 115  60 197  45  13  41]\n",
      " [  9  17  40  43  63  61  18 190   6  27]\n",
      " [127  79  40  19  11  12  11  13 197  66]\n",
      " [ 48 131  18  30   9  13   9  24  31 191]]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.074623  [    0/50000]\n",
      "loss: 1.261916  [ 5000/50000]\n",
      "loss: 1.234849  [10000/50000]\n",
      "loss: 1.420671  [15000/50000]\n",
      "loss: 1.523917  [20000/50000]\n",
      "loss: 1.266660  [25000/50000]\n",
      "loss: 1.361672  [30000/50000]\n",
      "loss: 1.353101  [35000/50000]\n",
      "loss: 1.187294  [40000/50000]\n",
      "loss: 1.414292  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 53.6%, Avg loss: 1.304339 \n",
      "\n",
      "[[190  32  63  13  27  11   3  16 118  35]\n",
      " [ 24 182   9  10   4   1   3   0  46  70]\n",
      " [ 44   5 127  34  55  30  18  16  19  11]\n",
      " [ 42  23  92 177  62 136  55  65  39  31]\n",
      " [ 33  12 146  83 182  87  57  86  12  17]\n",
      " [ 20  10  75 111  52 179  22  68   8  14]\n",
      " [ 29  41  94 118 128  66 196  43  20  39]\n",
      " [ 19  18  57  38  63  75  19 197  11  27]\n",
      " [ 62  35  23   5   5   4   4   2 196  21]\n",
      " [ 72 145  26  30  11  11  13  29  78 191]]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.201809  [    0/50000]\n",
      "loss: 1.299786  [ 5000/50000]\n",
      "loss: 1.286002  [10000/50000]\n",
      "loss: 1.417158  [15000/50000]\n",
      "loss: 1.165150  [20000/50000]\n",
      "loss: 1.218618  [25000/50000]\n",
      "loss: 1.190884  [30000/50000]\n",
      "loss: 1.194093  [35000/50000]\n",
      "loss: 1.554774  [40000/50000]\n",
      "loss: 1.188317  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.6%, Avg loss: 1.275999 \n",
      "\n",
      "[[187  23  59  21  27  13   3  19  67  27]\n",
      " [ 57 198  23  35  14  14   9   7  69 121]\n",
      " [ 38   5 124  30  41  44  14  11  13   8]\n",
      " [ 16   4  44 151  33 105  39  34  15  10]\n",
      " [ 33  11 173 105 192 114  79  81   8  15]\n",
      " [ 13   6  57 103  33 168  10  43   2   7]\n",
      " [ 21  19  79 126 104  68 196  41  11  32]\n",
      " [ 22  13  69  69  81 107  28 196  14  35]\n",
      " [134  59  54  23  16  19  10  11 196  58]\n",
      " [ 38  71  18  24   3  10  10  21  35 194]]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 1.159828  [    0/50000]\n",
      "loss: 1.119211  [ 5000/50000]\n",
      "loss: 1.526284  [10000/50000]\n",
      "loss: 1.483477  [15000/50000]\n",
      "loss: 1.463150  [20000/50000]\n",
      "loss: 1.224285  [25000/50000]\n",
      "loss: 1.372921  [30000/50000]\n",
      "loss: 1.045777  [35000/50000]\n",
      "loss: 0.994731  [40000/50000]\n",
      "loss: 1.136064  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 54.9%, Avg loss: 1.277391 \n",
      "\n",
      "[[187  23  64  18  27  14   5  18  80  30]\n",
      " [ 58 195  24  37  16  17  13   9  77 121]\n",
      " [ 39   5 125  29  39  34  14  12  11   6]\n",
      " [ 20   2  48 141  26  86  31  29   9   4]\n",
      " [ 29   5 156  94 191  97  57  91   4  12]\n",
      " [ 10   3  70 104  28 182  13  52   6   5]\n",
      " [ 21  11 101 128 126  75 196  49  15  17]\n",
      " [ 18   9  65  67  80  99  21 187  10  22]\n",
      " [105  37  39  14  12  17  10  10 192  32]\n",
      " [ 64  94  35  49   7  27  26  48  59 195]]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 1.247637  [    0/50000]\n",
      "loss: 1.535094  [ 5000/50000]\n",
      "loss: 1.031995  [10000/50000]\n",
      "loss: 1.089097  [15000/50000]\n",
      "loss: 1.060905  [20000/50000]\n",
      "loss: 1.095758  [25000/50000]\n",
      "loss: 1.309176  [30000/50000]\n",
      "loss: 1.173645  [35000/50000]\n",
      "loss: 1.229163  [40000/50000]\n",
      "loss: 1.316356  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.5%, Avg loss: 1.226115 \n",
      "\n",
      "[[194  42  77  28  34  14   7  21  93  31]\n",
      " [ 18 190   4   6   6   3   2   0  34  55]\n",
      " [ 43   5 168  44  81  58  36  22  12   8]\n",
      " [ 34  19  79 182  69 125  71  52  25  18]\n",
      " [ 14  12  94  64 178  52  58  48   4   8]\n",
      " [ 10   7  86 112  53 185  29  58   6   9]\n",
      " [  9  13  60  80  87  37 197  21   8  23]\n",
      " [ 23  15  71  65  97  86  28 196  10  30]\n",
      " [ 97  54  32  15  12  13   9   8 193  37]\n",
      " [ 67 154  28  38   7  13  26  29  58 198]]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 1.316551  [    0/50000]\n",
      "loss: 1.408438  [ 5000/50000]\n",
      "loss: 1.671320  [10000/50000]\n",
      "loss: 0.924464  [15000/50000]\n",
      "loss: 1.332283  [20000/50000]\n",
      "loss: 1.578743  [25000/50000]\n",
      "loss: 0.840955  [30000/50000]\n",
      "loss: 1.375255  [35000/50000]\n",
      "loss: 1.273966  [40000/50000]\n",
      "loss: 1.000861  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 56.8%, Avg loss: 1.230969 \n",
      "\n",
      "[[195  30  71  22  31  16   5  16 102  31]\n",
      " [ 20 191   6  11   6   4   3   0  46  44]\n",
      " [ 38   7 151  33  51  38  23  14   9   6]\n",
      " [ 33  13  79 179  55 126  70  41  24  17]\n",
      " [ 20  11 133  83 186  65  64  54   9  13]\n",
      " [ 12   5  84 112  43 183  33  66   7   6]\n",
      " [ 11  10  53  72  69  33 193  18   7  12]\n",
      " [ 27  18  82  66 107  89  38 192  11  27]\n",
      " [ 75  41  35  10   9  10   8   4 196  21]\n",
      " [ 83 158  35  52  16  27  44  44  91 198]]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 1.349210  [    0/50000]\n",
      "loss: 1.017367  [ 5000/50000]\n",
      "loss: 1.094899  [10000/50000]\n",
      "loss: 1.457239  [15000/50000]\n",
      "loss: 1.436176  [20000/50000]\n",
      "loss: 1.328081  [25000/50000]\n",
      "loss: 1.580061  [30000/50000]\n",
      "loss: 1.285703  [35000/50000]\n",
      "loss: 1.267316  [40000/50000]\n",
      "loss: 1.044011  [45000/50000]\n",
      "Test Error: \n",
      " Accuracy: 58.2%, Avg loss: 1.194879 \n",
      "\n",
      "[[190  36  80  33  40  26  10  35  80  40]\n",
      " [ 27 192  11  14  11  10  11   5  48  98]\n",
      " [ 55   6 175  63 100  70  39  30  13   9]\n",
      " [ 18   9  57 168  47 100  51  46  11  12]\n",
      " [  8   6  78  60 176  42  36  48   2   6]\n",
      " [ 15   6  81 122  57 184  24  70   7   8]\n",
      " [ 12  14  71  96  95  53 197  28  10  22]\n",
      " [  7   7  57  54  88  70  22 193   5  21]\n",
      " [124  74  45  30  17  22  12  14 193  63]\n",
      " [ 33  90  19  35   2  13  12  30  30 191]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# CNN の定義\n",
    "class CNN(torch.nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # モデルの重みの定義\n",
    "        self.relu = nn.ReLU()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=3)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3)\n",
    "        # self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(in_features=(8*8*8), out_features=10)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # 入力から出力を計算する\n",
    "        x = self.conv1(x)  # (30, 30, 16)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool1(x)  # (10, 10, 16)\n",
    "        x = self.conv2(x)  # (8, 8, 8)\n",
    "        x = self.relu(x)\n",
    "        # x = self.pool2(x)  # (4, 4, 8)\n",
    "        x = self.flatten(x)  # (8*8*8,)\n",
    "        x = self.fc(x)  # (10,)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_loop(model, dataloader, loss_fn, optimizer) -> None:\n",
    "    # 学習用関数の定義\n",
    "    num_classes = 10\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (x, y) in enumerate(dataloader):\n",
    "        pred = model(x)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(x)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "        \n",
    "def test_loop(model, dataloader, loss_fn) -> None:\n",
    "    # 評価用関数の定義\n",
    "    num_classes = 10\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in dataloader:\n",
    "            pred = model(x)\n",
    "            loss = loss_fn(pred, y)\n",
    "            test_loss += loss.item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            confusion_matrix[pred.argmax(1).detach().numpy(), y] += 1\n",
    "    \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    print(confusion_matrix)\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # CIFAR-10 データセットを読み込む\n",
    "    cifar10_data_train = torchvision.datasets.CIFAR10('./', train=True,  download=True, transform=torchvision.transforms.ToTensor())\n",
    "    cifar10_data_test  = torchvision.datasets.CIFAR10('./', train=False, download=True, transform=torchvision.transforms.ToTensor())\n",
    "    # DataLoader の設定\n",
    "    dataloader_train = torch.utils.data.DataLoader(cifar10_data_train, batch_size=50, shuffle=True)\n",
    "    dataloader_test  = torch.utils.data.DataLoader(cifar10_data_test,  batch_size=50, shuffle=True)\n",
    "    \n",
    "    cnn = CNN()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(cnn.parameters())\n",
    "    \n",
    "    epochs = 10\n",
    "    for i in range(epochs):\n",
    "        print(f\"Epoch {i+1}\\n-------------------------------\")\n",
    "        train_loop(cnn, dataloader_train, loss_fn, optimizer)\n",
    "        test_loop(cnn, dataloader_test, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20351e1-48bf-43fb-b46f-b13eb3da2e23",
   "metadata": {},
   "source": [
    "## リバーシAIへの応用\n",
    "\n",
    "* $400$ 入力、$400$ 出力のニューラルネットワークとして\n",
    "* 教師データの与え方は？\n",
    "  * 手で全部作る\n",
    "  * 人間と戦わせて作る（上とほぼ同義だが）\n",
    "  * アルゴリズムAIと戦わせて作る\n",
    "  * 自身や前の世代の自身と戦わせて作る\n",
    "* 全結合か、CNNか\n",
    "  * CNNで事足りるかわからない\n",
    "* 水増し、計算量削減\n",
    "  * 回転や反転、平行移動で得られる盤面とそのときの手を学習させる\n",
    "  * 盤面を何らかのアルゴリズムで正規化して回転や反転で得られる盤面を1つの状態に集約する"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
